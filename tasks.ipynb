{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principles of Data Analytics - Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Source the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sourcing the data for use during the module.\n",
    "\n",
    "The Iris dataset can be found here: https://gist.github.com/curran/a08a1080b88344b0c8a7\n",
    "\n",
    "A way to make it easier for the csv to be read easier is found here: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frames.\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning Library that contains example datasets.\n",
    "import sklearn as skl\n",
    "\n",
    "# Import other libraries that will help with visualising and analysing data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data frames and machine learning libraries have been imported. It's now time to import the dataset using read.csv. This will be task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will load in the iris dataset from the web link.\n",
    "\n",
    "df = pd.read_csv(\"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Explore the Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to check that the dataset is actually loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the dataset.\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, need to check the shape of the data, this will help further along when deciding the types of exploratory statistical tests to conduct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 150 samples, each of these samples has had a number of measurements taken (5 variables in all) - sepal width and length, petal width and length, and species of iris. Based on Stevens (1946) categarisation of data types, these are forms of ratio (length and width measurements), and nominal (species). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ease analysis it may be plausible to standardise the dataset, particularly the measurements. This may aid in analysis further down the line. Could do a tukeys analysis later to see if there is significant diference in petal/sepal length and/or width, between the species depending on iris species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and last 5 rows of the dataset are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df = pd.concat([df.head(5), df.tail(5)])\n",
    "print(sliced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting some information on what is included in the dataset. Although I have previously stated that the data is ratio and nominal. This will clarify the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information table, it can be seen that one column has categorical (nominal) data (species column) and all the other columns are of the numeric type with non-Null entriesm that is, there are no 0 / null~ entries in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking for null values and the different data types, now checking for missing values is important. If there were missing values, the dataset would need to be cleaned and sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following a checking of the dataset, it was found that there were no missing values in any of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the data is correct and contains no repitition of recorded values it was important to check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop_duplicates(subset =\"species\",)\n",
    "\n",
    "print(data.species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates were found in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it was important to check if the dataset was balanced to ensure that the analysis isn't skewed by the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts(\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that all the species contain equal amounts of rows, thus the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Summarize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next - quick statistical summary of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Visualize Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Investigate Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Analyze Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Analyze Class Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Compute Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Fit a Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Too Many Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stevens, S. S. 1946. On the Theory of Scales of Measurement. Science, Vol. 103, No. 2648. http://expsylab.psych.uoa.gr/fileadmin/expsylab.psych.uoa.gr/uploads/papers/Stevens_1946.pdf\n",
    "\n",
    "Python. 2025. Built-in types. https://docs.python.org/3/library/stdtypes.html\n",
    "\n",
    "Stackoverflow user \"Life is complex\". First and last n rows of a dataframe. https://stackoverflow.com/questions/58260771/how-to-show-firstlast-n-rows-of-a-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELP DOCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/iris-dataset/\n",
    "\n",
    "https://www.geeksforgeeks.org/exploratory-data-analysis-on-iris-dataset/\n",
    "\n",
    "https://stackoverflow.com/questions/58260771/how-to-show-firstlast-n-rows-of-a-dataframe\n",
    "\n",
    "https://bytemedirk.medium.com/mastering-iris-dataset-analysis-with-python-9e040a088ef4\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html\n",
    "\n",
    "https://medium.com/@kachiann/a-beginners-guide-to-machine-learning-with-python-iris-flower-prediction-61814e095268\n",
    "\n",
    "https://www.geeksforgeeks.org/python-basics-of-pandas-using-iris-dataset/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

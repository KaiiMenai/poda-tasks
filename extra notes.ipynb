{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for importing the libraries for dataset analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next need to load in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/iris.json'\n",
    "df = pd.read_json(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Basic Data Exploration\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next want to actually see the data - visualise it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Visualization\n",
    "# Pairplot colored by species\n",
    "sns.pairplot(df, hue='species', height=2.5)\n",
    "plt.suptitle(\"Pairwise Feature Relationships\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating the data by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Boxplots by species\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, feature in enumerate(['sepalLength', 'sepalWidth', 'petalLength', 'petalWidth']):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.boxplot(x='species', y=feature, data=df)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conducting correlartion analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Correlation Analysis\n",
    "corr_matrix = df.iloc[:, :4].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Principal Component Analysis\n",
    "X = df.iloc[:, :4]\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardising the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA again but on the standardised data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the PCA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize PCA results\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=principal_components[:, 0], y=principal_components[:, 1], \n",
    "                hue=df['species'], palette='viridis', s=100)\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "plt.title(\"PCA of Iris Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Predictive Modeling\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the LRM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model - how good is it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion martrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', \n",
    "            xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key findings from this analysis:\n",
    "\n",
    "Data Structure:\n",
    "\n",
    "150 samples with 4 features (all numerical)\n",
    "\n",
    "3 balanced classes (50 samples per species)\n",
    "\n",
    "No missing values\n",
    "\n",
    "Feature Relationships:\n",
    "\n",
    "Petal measurements show strong positive correlation (r=0.96)\n",
    "\n",
    "Sepal width has lowest correlation with other features\n",
    "\n",
    "Setosa is distinctly different in petal measurements\n",
    "\n",
    "PCA Insights:\n",
    "\n",
    "First 2 components explain 95.8% of variance\n",
    "\n",
    "PC1 (73% variance) strongly correlates with petal measurements\n",
    "\n",
    "PC2 (22.8% variance) relates to sepal width\n",
    "\n",
    "Model Performance:\n",
    "\n",
    "Logistic regression achieves ~97% accuracy\n",
    "\n",
    "Virginica shows slightly lower recall due to overlap with Versicolor\n",
    "\n",
    "Most confusion occurs between Versicolor and Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is each step conducted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "Establishes the foundation of analysis by importing raw data\n",
    "\n",
    "JSON format preserves data structure from the source\n",
    "\n",
    "Pandas DataFrames enable easy data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.head(), df.dtypes, df.describe(), value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    ".head(): Quick visual check of data structure/format\n",
    "\n",
    ".dtypes: Verify numerical vs categorical data types\n",
    "\n",
    ".describe(): Understand distributions/ranges of features\n",
    "\n",
    ".value_counts(): Check class balance for modeling fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "Reveals pairwise feature relationships\n",
    "\n",
    "Identifies separable clusters visually\n",
    "\n",
    "Shows how features interact across species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='species', y=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    "Compares value distributions across classes\n",
    "\n",
    "Identifies potential outliers\n",
    "\n",
    "Shows median/quartile differences between species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "Measures linear relationships between features\n",
    "\n",
    "Helps identify redundant variables (high correlation)\n",
    "\n",
    "Informs feature selection for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "PCA is variance-sensitive - scaling prevents bias toward high-magnitude features\n",
    "\n",
    "Ensures all features contribute equally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    "Reduces 4D data to 2D for visualization\n",
    "\n",
    "Identifies latent patterns/directions of maximum variance\n",
    "\n",
    "Helps confirm if species separation is possible with fewer dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "Evaluates model performance on unseen data\n",
    "\n",
    "Prevents overfitting to training data\n",
    "\n",
    "Standard practice for reliable accuracy estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason:\n",
    "\n",
    "Simple baseline for multi-class classification\n",
    "\n",
    "Interpretable coefficients\n",
    "\n",
    "Works well with small, linearly separable datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "classification_report(), confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    "Precision/Recall: Measures class-specific performance\n",
    "\n",
    "F1-score: Balanced metric for imbalanced classes (though Iris is balanced)\n",
    "\n",
    "Confusion Matrix: Visualizes error patterns between similar classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Strategic Reasons:\n",
    "1. Sequential Analysis:\n",
    "- Progress from simple → complex techniques\n",
    "- Validate assumptions at each stage before proceeding\n",
    "\n",
    "2. Defensive Programming:\n",
    "- Checking dtypes prevents analysis errors\n",
    "- Class distribution check ensures valid modeling\n",
    "\n",
    "3. Visual Verification:\n",
    "- Humans process visual patterns better than numbers\n",
    "- Helps catch anomalies statistics might miss\n",
    "\n",
    "4. Dimensionality Reduction:\n",
    "- PCA validates if essential information is preserved in fewer dimensions\n",
    "- Guides feature engineering decisions\n",
    "\n",
    "5. Model Interpretability:\n",
    "- Logistic regression provides coefficients showing feature importance\n",
    "- Simple models establish performance baselines before trying complex ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow follows the standard data science process:\n",
    "Data Understanding → Exploration → Preprocessing → Modeling → Evaluation\n",
    "\n",
    "Each step builds foundational knowledge needed for subsequent analysis while guarding against common pitfalls like scale sensitivity (PCA), overfitting (train-test split), and misinterpretation (visual verification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAIRPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "url = \"https://datahub.io/machine-learning/iris/r/iris.csv\"\n",
    "iris_data = pd.read_csv(url)\n",
    "\n",
    "# Create a pairplot\n",
    "sns.pairplot(iris_data, hue='class')\n",
    "plt.suptitle('Pair Plot of Iris Dataset Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pairplot is a powerful visualization tool that provides a comprehensive overview of the relationships between multiple variables in a dataset. In the context of the Iris dataset, the pairplot depicts the following:\n",
    "\n",
    "Scatter plots: The pairplot creates a grid of scatter plots, where each variable is plotted against every other variable. This allows you to see how each feature (sepal length, sepal width, petal length, and petal width) relates to the others.\n",
    "\n",
    "Distribution plots: Along the diagonal of the grid, you'll find distribution plots (usually histograms or kernel density estimates) for each individual variable. These show the distribution of values for each feature.\n",
    "\n",
    "Color-coded by species: Each data point is color-coded based on the iris species (setosa, versicolor, or virginica). This helps visualize how well the different species can be separated based on their features.\n",
    "\n",
    "Relationships and patterns: The pairplot allows you to quickly identify any linear or non-linear relationships between variables, as well as any clustering or separation of the different iris species.\n",
    "\n",
    "Feature interactions: By examining the scatter plots, you can see how combinations of features might be useful for distinguishing between the different iris species.\n",
    "\n",
    "Outliers and anomalies: The pairplot can help identify any potential outliers or unusual patterns in the dataset.\n",
    "\n",
    "By analyzing the pairplot, you can gain insights into which features or combinations of features might be most useful for classifying the iris species, and how well the species can be separated based on these measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To calculate the coefficient of determination (R^2), you can use the following steps:\n",
    "\n",
    "Calculate the total sum of squares (SST):\n",
    "SST = \\sum (y_i - y_mean)^2\n",
    "\n",
    "Calculate the sum of squared residuals (SSR):\n",
    "SSR = \\sum (y_i - y_pred_i)^2\n",
    "\n",
    "Apply the formula:\n",
    "R^2 = 1 - (SSR / SST)\n",
    "\n",
    "Here's a Python implementation using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_r_squared(y_true, y_pred):\n",
    "    y_mean = np.mean(y_true)\n",
    "    sst = np.sum((y_true - y_mean)**2)\n",
    "    ssr = np.sum((y_true - y_pred)**2)\n",
    "    r_squared = 1 - (ssr / sst)\n",
    "    return r_squared\n",
    "\n",
    "# Example usage\n",
    "y_true = np.array([3, 35, 64, 223, 91, 44, 9.3, 12])\n",
    "y_pred = np.array([5, 32, 60, 220, 95, 40, 10, 15])\n",
    "\n",
    "r_squared = calculate_r_squared(y_true, y_pred)\n",
    "print(f\"R-squared: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 value ranges from 0 to 1, where:\n",
    "\n",
    "0 indicates that the model explains none of the variability in the data\n",
    "\n",
    "1 indicates that the model explains all the variability\n",
    "\n",
    "Alternatively, you can use scikit-learn's r2_score function for a more robust implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r_squared = r2_score(y_true, y_pred)\n",
    "print(f\"R-squared: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting R^2:\n",
    "\n",
    "R^2 = 0.7176 means that 71.76% of the variance in the dependent variable is predictable from the independent variable(s).\n",
    "\n",
    "Values above 0.25 are generally considered to indicate a large effect size.\n",
    "\n",
    "Remember that R^2 alone doesn't imply causation and should be used alongside other metrics for a comprehensive model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

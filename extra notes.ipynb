{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is each step conducted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "Establishes the foundation of analysis by importing raw data\n",
    "\n",
    "JSON format preserves data structure from the source\n",
    "\n",
    "Pandas DataFrames enable easy data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(), df.dtypes, df.describe(), value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    ".head(): Quick visual check of data structure/format\n",
    "\n",
    ".dtypes: Verify numerical vs categorical data types\n",
    "\n",
    ".describe(): Understand distributions/ranges of features\n",
    "\n",
    ".value_counts(): Check class balance for modeling fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "Reveals pairwise feature relationships\n",
    "\n",
    "Identifies separable clusters visually\n",
    "\n",
    "Shows how features interact across species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='species', y=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    "Compares value distributions across classes\n",
    "\n",
    "Identifies potential outliers\n",
    "\n",
    "Shows median/quartile differences between species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "Measures linear relationships between features\n",
    "\n",
    "Helps identify redundant variables (high correlation)\n",
    "\n",
    "Informs feature selection for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "PCA is variance-sensitive - scaling prevents bias toward high-magnitude features\n",
    "\n",
    "Ensures all features contribute equally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    "Reduces 4D data to 2D for visualization\n",
    "\n",
    "Identifies latent patterns/directions of maximum variance\n",
    "\n",
    "Helps confirm if species separation is possible with fewer dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why:\n",
    "\n",
    "Evaluates model performance on unseen data\n",
    "\n",
    "Prevents overfitting to training data\n",
    "\n",
    "Standard practice for reliable accuracy estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason:\n",
    "\n",
    "Simple baseline for multi-class classification\n",
    "\n",
    "Interpretable coefficients\n",
    "\n",
    "Works well with small, linearly separable datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(), confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    "Precision/Recall: Measures class-specific performance\n",
    "\n",
    "F1-score: Balanced metric for imbalanced classes (though Iris is balanced)\n",
    "\n",
    "Confusion Matrix: Visualizes error patterns between similar classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Strategic Reasons:\n",
    "1. Sequential Analysis:\n",
    "- Progress from simple → complex techniques\n",
    "- Validate assumptions at each stage before proceeding\n",
    "\n",
    "2. Defensive Programming:\n",
    "- Checking dtypes prevents analysis errors\n",
    "- Class distribution check ensures valid modeling\n",
    "\n",
    "3. Visual Verification:\n",
    "- Humans process visual patterns better than numbers\n",
    "- Helps catch anomalies statistics might miss\n",
    "\n",
    "4. Dimensionality Reduction:\n",
    "- PCA validates if essential information is preserved in fewer dimensions\n",
    "- Guides feature engineering decisions\n",
    "\n",
    "5. Model Interpretability:\n",
    "- Logistic regression provides coefficients showing feature importance\n",
    "- Simple models establish performance baselines before trying complex ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow follows the standard data science process:\n",
    "Data Understanding → Exploration → Preprocessing → Modeling → Evaluation\n",
    "\n",
    "Each step builds foundational knowledge needed for subsequent analysis while guarding against common pitfalls like scale sensitivity (PCA), overfitting (train-test split), and misinterpretation (visual verification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAIRPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "url = \"https://datahub.io/machine-learning/iris/r/iris.csv\"\n",
    "iris_data = pd.read_csv(url)\n",
    "\n",
    "# Create a pairplot\n",
    "sns.pairplot(iris_data, hue='class')\n",
    "plt.suptitle('Pair Plot of Iris Dataset Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pairplot is a powerful visualization tool that provides a comprehensive overview of the relationships between multiple variables in a dataset. In the context of the Iris dataset, the pairplot depicts the following:\n",
    "\n",
    "Scatter plots: The pairplot creates a grid of scatter plots, where each variable is plotted against every other variable. This allows you to see how each feature (sepal length, sepal width, petal length, and petal width) relates to the others.\n",
    "\n",
    "Distribution plots: Along the diagonal of the grid, you'll find distribution plots (usually histograms or kernel density estimates) for each individual variable. These show the distribution of values for each feature.\n",
    "\n",
    "Color-coded by species: Each data point is color-coded based on the iris species (setosa, versicolor, or virginica). This helps visualize how well the different species can be separated based on their features.\n",
    "\n",
    "Relationships and patterns: The pairplot allows you to quickly identify any linear or non-linear relationships between variables, as well as any clustering or separation of the different iris species.\n",
    "\n",
    "Feature interactions: By examining the scatter plots, you can see how combinations of features might be useful for distinguishing between the different iris species.\n",
    "\n",
    "Outliers and anomalies: The pairplot can help identify any potential outliers or unusual patterns in the dataset.\n",
    "\n",
    "By analyzing the pairplot, you can gain insights into which features or combinations of features might be most useful for classifying the iris species, and how well the species can be separated based on these measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To calculate the coefficient of determination (R^2), you can use the following steps:\n",
    "\n",
    "Calculate the total sum of squares (SST):\n",
    "SST = \\sum (y_i - y_mean)^2\n",
    "\n",
    "Calculate the sum of squared residuals (SSR):\n",
    "SSR = \\sum (y_i - y_pred_i)^2\n",
    "\n",
    "Apply the formula:\n",
    "R^2 = 1 - (SSR / SST)\n",
    "\n",
    "Here's a Python implementation using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_r_squared(y_true, y_pred):\n",
    "    y_mean = np.mean(y_true)\n",
    "    sst = np.sum((y_true - y_mean)**2)\n",
    "    ssr = np.sum((y_true - y_pred)**2)\n",
    "    r_squared = 1 - (ssr / sst)\n",
    "    return r_squared\n",
    "\n",
    "# Example usage\n",
    "y_true = np.array([3, 35, 64, 223, 91, 44, 9.3, 12])\n",
    "y_pred = np.array([5, 32, 60, 220, 95, 40, 10, 15])\n",
    "\n",
    "r_squared = calculate_r_squared(y_true, y_pred)\n",
    "print(f\"R-squared: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 value ranges from 0 to 1, where:\n",
    "\n",
    "0 indicates that the model explains none of the variability in the data\n",
    "\n",
    "1 indicates that the model explains all the variability\n",
    "\n",
    "Alternatively, you can use scikit-learn's r2_score function for a more robust implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r_squared = r2_score(y_true, y_pred)\n",
    "print(f\"R-squared: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting R^2:\n",
    "\n",
    "R^2 = 0.7176 means that 71.76% of the variance in the dependent variable is predictable from the independent variable(s).\n",
    "\n",
    "Values above 0.25 are generally considered to indicate a large effect size.\n",
    "\n",
    "Remember that R^2 alone doesn't imply causation and should be used alongside other metrics for a comprehensive model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features: sepal/petal length/width\n",
    "y = iris.target  # Target: species (0=setosa, 1=versicolor, 2=virginica)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Example prediction\n",
    "new_measurement = [[5.1, 3.5, 1.4, 0.2]]  # Example input\n",
    "predicted_species = model.predict(new_measurement)\n",
    "print(f\"Predicted Species: {iris.target_names[predicted_species][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key components explained:\n",
    "\n",
    "Variable Selection: Uses sepal length (independent) to predict sepal width (dependent) based on common practice in search results\n",
    "\n",
    "Data Splitting: 80-20 split ensures model validation on unseen data\n",
    "\n",
    "Model Training: fit() method calculates optimal slope and intercept\n",
    "\n",
    "Equation: ŷ = -0.223x + 3.419 (from coefficients in)\n",
    "\n",
    "Evaluation: R² score shows ~71.76% variance explained\n",
    "\n",
    "Interpretation of results:\n",
    "\n",
    "Negative slope (-0.223) indicates inverse relationship: as sepal length increases, sepal width tends to decrease\n",
    "\n",
    "Model explains significant portion of variance (R² > 0.7) but not perfect fit\n",
    "\n",
    "Residuals show some non-linear patterns, suggesting potential for polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiple regression (extension):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all features to predict one variable\n",
    "X = iris.data[:, [0,2,3]]  # Sepal length, petal length, petal width\n",
    "y = iris.data[:, 1]        # Sepal width\n",
    "\n",
    "multi_model = LinearRegression()\n",
    "multi_model.fit(X_train, y_train)\n",
    "print(f\"Multiple R²: {multi_model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This follows the same pattern but uses multiple predictors. The search results suggest this approach while maintaining the core linear regression methodology shown in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
